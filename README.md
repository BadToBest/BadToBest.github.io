# BadToBest Team
We are a group of algorithm engineers from the Terminal Technology Department of Ant Group, and we are very pleased to communicate with everyone.

# Open Source Projects
* EchoMimicV1: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditioning. [GitHub](https://github.com/antgroup/echomimic)
* EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation. [GitHub](https://github.com/antgroup/echomimic_v2)

# Publications
1. Chen, Z., Cao, J., Chen, Z., Li, Y., & Ma, C. (2024). EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions. arXiv preprint arXiv:2407.08136.
2. Chai, W., Zheng, D., Cao, J., Chen, Z., Wang, C., & Ma, C. (2023). SpeedUpNet: A Plug-and-Play Hyper-Network for Accelerating Text-to-Image Diffusion Models. arXiv preprint arXiv:2312.08887.
3. Cao, J., Liu, Y., Bai, W., Ding, J., & Li, L. (2023, June). Nasty-SFDA: Source free domain adaptation from a nasty model. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE.
4. Xu, Y., Meng, L., Peng, R., Yin, Y., Ding, J., Li, L., & Wu, D. (2023, June). Cross-Modal Diversity-Based Active Learning for Multi-Modal Emotion Estimation. In 2023 International Joint Conference on Neural Networks (IJCNN) (pp. 1-8). IEEE.
5. Li, S., Xu, Y., Wu, H., Wu, D., Yin, Y., Cao, J., & Ding, J. (2022, October). Facial Expression Recognition In-the-Wild with Deep Pre-trained Models. In European Conference on Computer Vision (pp. 181-190). Cham: Springer Nature Switzerland.
6. Xu, Y., Cui, Y., Jiang, X., Yin, Y., Ding, J., Li, L., & Wu, D. (2022). Inconsistency-based multi-task cooperative learning for emotion recognition. IEEE Transactions on Affective Computing, 13(4), 2017-2027.
7. Li, S., Xu, Y., Wu, H., Wu, D., Yin, Y., Cao, J., & Ding, J. (2022, October). Facial Expression Recognition In-the-Wild with Deep Pre-trained Models. In European Conference on Computer Vision (pp. 181-190). Cham: Springer Nature Switzerland.
8. Wang, L., Chen, Z., Yu, T., Ma, C., Li, L., & Liu, Y. (2022). Faceverse: a fine-grained and detail-controllable 3d face morphable model from a hybrid dataset. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 20333-20342).
9. Cao, J., Liu, Y., Ding, J., & Li, L. (2022, October). Self-supervised face anti-spoofing via anti-contrastive learning. In Chinese Conference on Pattern Recognition and Computer Vision (PRCV) (pp. 479-491). Cham: Springer Nature Switzerland.
10. Li, S., Xu, Y., Wu, H., Wu, D., Yin, Y., Cao, J., & Ding, J. (2022). Facial affect analysis: Learning from synthetic data & multi-task learning challenges. arXiv preprint arXiv:2207.09748.
11. Liu, Y., Cao, J., Li, B., Hu, W., Ding, J., & Li, L. (2022). Cross-architecture knowledge distillation. In Proceedings of the Asian conference on computer vision (pp. 3396-3411).
12. Zheng, D., Liu, Y., & Li, L. (2022). Leveraging inter-layer dependency for post-training quantization. Advances in Neural Information Processing Systems, 35, 6666-6679.
